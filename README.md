# PFC2 - ACMC+
La tarea de reconocer emociones en expresiones faciales en espacios controlados es un problema que no está resuelto de forma óptima. La aplicación de esta tarea es de suma importancia, ya que permite obtener una retroalimentación fidedigna de la experiencia del usuario con algún dispositivo. Con el avance del aprendizaje profundo en el campo de visión por computador, se pueden implementar modelos que logren hitos de exactitud más altos. En esta tesis se propone la aplicación de aumentación de datos, a través de transformaciones de rotación, brillo, contraste e inversión de la imagen, con el objetivo de balancear el conjunto de datos y permitir que el modelo aprenda adecuadas las características de todas las expresiones del conjunto de datos. Además, se propone una red de atención cruzada multi cabezal con aumentación de datos para extraer todas las características de los rostros que permitan clasificar con mayor exactitud las expresiones. La red tiene tres componentes: el primer componente, FCN, extrae las características más robustas; el segundo componente, MAN, detecta características relevantes en diferentes zonas faciales; y el último componente, AFN, fusiona de forma ordenada los mapas de atención obtenidos del componente anterior. El modelo será evaluado con el conjunto de datos RAF-DB. 
